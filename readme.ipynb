{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目为帮助初学者入门profile工作所编写，是本组针对主流的profile工具所设计和编写的，包括一些小型模型以测试对于profiling的理解。如有不周到之处请谅解，我们也将不断完善该文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NVIDIA Nsight Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您如果需要安装NVIDIA Nsight，可以在https://developer.nvidia.com/tools-overview/nsight-compute/get-started，网址上获取安装包进行安装，安装流程省略。Nsight Compute 工具将其测量库插入到应用程序进程中，这允许分析器拦截与CUDA用户模式驱动程序的通信。此外，当检测到内核启动时，库可以从GPU收集所请求的性能指标。然后将结果传输回前端。Nsight Compute主要是针对CUDA Kernel较少的程序设计的，适合小型程序的profiling工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ncu常用指令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最直接且常用的用法是下面两个命令，如想了解详细解释，可见各细节部分<br>\n",
    "ncu --set full -o profile_result ./application<br>\n",
    "ncu --set default -o profile_result python your_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 基础性能分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ncu --set full -o profile_result ./application</b> <br>\n",
    "<br>\n",
    "<b>--set参数</b>：<br>default（基础性能概览：包含内核启动统计、占用率和GPU吞吐量等约35个核心指标，分析开销较小，适合初步性能评估）<br>detailed（深入性能分析：在default基础上增加了指令统计、内存工作负载分析和Warp状态统计等，提供约157个更详细的指标，用于深入探究性能瓶颈根源）<br>full（全面数据收集：提供最全面的指标（约162个），包含更详尽的内存工作负载图表和数据表。对系统开销最大，通常用于深度优化）<br>source（源代码关联分析：专注于约47个与源代码映射相关的性能计数器，需要编译时使用-lineinfo等选项生成调试信息，便于进行指令级优化）<br>\n",
    "<br>\n",
    "<b>-o参数</b>：profile_result为输出报告文件的名字 <br>\n",
    "<br>\n",
    "<b>./application</b>为需要执行的程序 <br>\n",
    "<br>\n",
    "完成后会在服务器上产生一个名称为profile_result.ncu-rep的文件，可以在本地用NVIDIA Nsight Compute打开 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 指标收集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ncu --metrics dram__bytes.sum.per_second -o profile_result ./application</b><br>\n",
    "<br>\n",
    "<b>--metrics参数</b>：用以收集特定的指标，可以使用逗号分隔不同指标或使用正则表达式<br>\n",
    "<br>\n",
    "可以使用ncu --query-metrics命令查询所有可用的指标。<br>\n",
    "<br>\n",
    "常用的指标有：<br>\n",
    "sm__cycles_active.avg.pct_of_peak_sustained_elapsed，SM活跃周期占比<br>\n",
    "sm__warps_active.avg.pct，活跃Warp百分比<br>\n",
    "dram__bytes.sum.per_second，显存带宽使用率<br>\n",
    "smsp__sass_thread_inst_executed_op_fadd_pred_on.sum，已执行的特定类型指令（如浮点加法）数量<br>\n",
    "Occupancy，理论占用率与实际占用率差距过大常表明工作负载不均衡<br>\n",
    "l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum，全局内存加载请求数<br>\n",
    "l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum，全局内存存储请求数，分析缓存局部性<br>\n",
    "<br>\n",
    "第一行的命令完成后即收集完成内存带宽指标，结果输出到指定文件当中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 结果过滤与聚焦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ncu -k \"my_kernel\" -o profile_result ./application</b><br>\n",
    "<br>\n",
    "“my_kernel”处指定需要详细分析的内核函数，如何获得内核名称？<br>\n",
    "直接运行一次 ncu (例如使用 --set default)，其输出的 \"Section: Compute Workload Analysis\" 部分会列出所有捕获到的内核名称，下面也会讲Compute Workload Analysis。您也可以使用正则表达式匹配多个kernel<br>\n",
    "<br>\n",
    "最终输出的报告专注于你筛选出的内核。例如，如果你使用 -k \"vectorAdd\"，那么报告里你只会看到名为 vectorAdd 的内核的详细性能分析；如果你的程序多次启动了同一个内核，Nsight Compute 默认可能会捕获多次启动的数据。最终的报告通常会汇总这些多次执行的数据（例如平均值），或者在时间线中展示多次调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 输出与控制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ncu --csv -o report.csv ./application</b><br>\n",
    "<br>\n",
    "使用 ncu --csv -o report.csv ./application 命令后，得到的 CSV 文件内容会直接反映 Nsight Compute 的性能分析结果。<br>\n",
    "各列通常包括：<br>\n",
    "内核标识信息：例如 ID，Process ID，Process Name，Kernel Name，Context ID 等，用于区分不同的内核和其启动实例。<br>\n",
    "性能指标数据：核心的性能指标列，其名称直接来自您使用 --metrics 指定的指标，或所选 --set 规则集包含的指标。例如 sm__cycles_active.avg.pct (SM 活跃周期百分比)，dram__bytes.sum.per_second (显存带宽)，l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum (全局加载请求数) 等。<br>\n",
    "其他元数据：可能包括 Grid Size，Block Size，Registers Per Thread，Static Shared Memory 等内核配置信息。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 如何使用ncu运行某个python文件？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ncu -o my_profile python your_script.py</b><br>\n",
    "以上是基本用法，若需要其他更多的参数进行profile工作，可类比上述参数添加更多的分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 界面介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![界面总览](./images/view.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图为界面的总览图，只需要将在服务器上生成的ncu文件下载后，拖动到NVIDIA Nsight Compute界面上，即可获知详细的profile报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Summary概览图](./images/summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "序号 0-8 则是依次运算的kernel，其信息包括：<br>\n",
    "ID: 每个函数的唯一标识符。<br>\n",
    "Estimated Speedup: 估计的加速比，表示如果优化这个函数可能带来的速度提升。<br>\n",
    "Function Name: 函数的名称。<br>\n",
    "Demangled Name: 去掉修饰符的函数名称。<br>\n",
    "Duration: 函数执行时间（以ns为单位）。<br>\n",
    "Runtime Improvement: 估计的运行时间提示（以ns为单位），表示如果优化这个函数可能带来的运行时间提升。<br>\n",
    "Compute Throughput: 计算吞吐量。SM 吞吐量假设在 SMSPs 间负载平衡理想的情况下 （此吞吐量指标表示在所有子单元实例的经过周期内达到的峰值持续率的百分比）。<br>\n",
    "Memory Throughput: 内存吞吐量。计算内存管道吞吐量 （此吞吐量指标表示在所有子单元实例的经过周期内达到的峰值持续率的百分比）。<br>\n",
    "Registers: 每个线程使用的寄存器数量。<br>\n",
    "GridSize：kernel启动的网格大小。<br>\n",
    "BlockSize：每个Block的线程数。<br>\n",
    "Cycles：GPC指令周期。GPC：通用处理集群（General Processing Cluster）包含以 TPC（纹理处理集群）形式存在的 SM、纹理和 L1 缓存。 它在芯片上被多次复制。<br>\n",
    "最上部的Result默认显示的是ID=0的 kernel 运行的部分信息，包括GPU型号及频率<br>\n",
    "并且，从该图可以初步得到一些信息，比如大概率memory-bound ID8，大概率compute-bound ID7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 GPU Speed Of Light Throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![throughput-1](./images/throughput-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "左侧指标可以详细看到 Compute 和 不同层次的 Memory 的实际利用效率的情况，由此可以定位其在 roofline 中的位置。<br>\n",
    "从这个结果可以看出：<br>\n",
    "内存吞吐量(40.27%)高于计算吞吐量(32.70%)，表明这可能是一个内存密集型任务。<br>\n",
    "L2 缓存和 DRAM 吞吐量相对较低，可能存在优化空间。<br>\n",
    "L1吞吐量与总体内存吞吐量相近，说明主要的内存操作与该部分交互，需要特别说明的是 Shared memory 也统计在内。<br>\n",
    "<br>\n",
    "右侧指标说明了执行时间、总的周期数、SM活跃的周期数以及SM和DRAM的频率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![throughput-2](./images/throughput-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![throughput-3](./images/throughput-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后这部分是roofiline model的一个绘制，绿色的点在斜线下面，可以很直观地判断出该kernel是memory bound的一个内核"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Memory Workload Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![memory-1](./images/memory-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该指标为内存资源的使用情况，主要包括通信带宽、内存指令的最大吞吐量。详细的数据表如上：<br>\n",
    "<br>\n",
    "Memory Throughput: 34.63 Gbyte/s<br>\n",
    "即每秒在DRAM中访问的字节数。<br>\n",
    "<br>\n",
    "L1/TEX Hit Rate: 74.01%<br>\n",
    "每个 sector 的 sector 命中次数 （这个比率指标表示跨所有子单元实例的值，以百分比表示）。<br>\n",
    "<br>\n",
    "l1tex：一级（L1）/纹理缓存位于GPC内部。 它可以用作定向映射的共享内存和/或在其缓存部分存储全局、本地和纹理数据。<br>\n",
    "<br>\n",
    "sector：缓存线或设备内存中对齐的32字节内存块。 一个L1或L2缓存线是四个sector，即128字节。 如果标签存在且sector数据在缓存线内，则sector访问被归类为命中。 标签未命中和标签命中但数据未命中都被归类为未命中。<br>\n",
    "<br>\n",
    "L2 Hit Rate: 87.19%<br>\n",
    "L2sector查找命中的比例 （这个比率指标表示跨所有子单元实例的值，以百分比表示）。<br>\n",
    "<br>\n",
    "l2s：二级（L2）缓存切片是二级缓存的一个子分区。 l2s_t 指的是其标签阶段。 l2s_m 指的是其未命中阶段。 l2s_d 指的是其数据阶段。<br>\n",
    "<br>\n",
    "Mem Busy: 40.27%<br>\n",
    "缓存和DRAM内部活动的吞吐量（这个吞吐量指标表示在所有子单元实例的经过周期内达到的峰值持续速率的百分比）<br>\n",
    "<br>\n",
    "Max Bandwidth: 17.53%<br>\n",
    "SM<->缓存<->DRAM之间互连的吞吐量 （这个吞吐量指标表示在所有子单元实例的经过周期内达到的峰值持续速率的百分比）<br>\n",
    "<br>\n",
    "L2 Compression Ratio: 0\n",
    "L2 Compression Success Rate: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![memory-2](./images/memory-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图显示了各级 memory 的连接关系及使用情况，整体情况一目了然。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![memory-3](./images/memory-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上图中，我们主要关心load和store的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![memory-4](./images/memory-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上图中，我们也主要关心load和store的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Compute Workload Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![compute-1](./images/compute-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析完了内存的情况后，接下来分析计算单元的使用情况。即对流式多处理器（SM）的计算资源进行详细分析，包括实际达到的每时钟周期指令数（IPC）以及每个可用流水线的利用率。主要指标包括：<br>\n",
    "<br>\n",
    "Executed Ipc Elapsed: 1.30 inst/cycle<br>\n",
    "执行的warp指令数，此计数器指标表示所有子单元实例中每个执行周期的平均操作数。<br>\n",
    "<br>\n",
    "Executed Ipc Active: 1.72 inst/cycle<br>\n",
    "执行的warp指令数，此计数器指标表示所有子单元实例中每个活动周期的平均操作数。<br>\n",
    "<br>\n",
    "Issued Ipc Active: 1.73 inst/cycle<br>\n",
    "发出的warp指令数，此计数器指标表示所有子单元实例中每个活动周期的平均操作数。与上一项比较可知，在活动周期内发出的指令都被执行。<br>\n",
    "<br>\n",
    "SM Busy<br>\n",
    "假设SMSP间理想负载平衡的SM核心指令吞吐量，此吞吐量指标表示在所有子单元实例的活动周期内达到的峰值持续率的百分比。<br>\n",
    "<br>\n",
    "SMSPs: 每个SM被划分为四个处理块，称为SM子分区。 SM子分区是SM上的主要处理元素。 一个子分区管理固定大小的warp池。<br>\n",
    "<br>\n",
    "Issue Slots Busy<br>\n",
    "发出的warp指令数，此计数器指标表示在所有子单元实例的活动周期内达到的峰值持续率的平均百分比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![compute-2](./images/compute-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是一些主要计算单元的利用率情况，先分别介绍一下这些计算单元：<br>\n",
    "\n",
    "FMA: Fused Multiply Add/Accumulate，融合乘加。FMA流水线处理大多数FP 32算法（FADD、FMUL、FMAD）。它还执行整数乘法运算（IMUL、IMAD）以及整数点积。<br>\n",
    "ALU: Arithmetic Logic Unit, 算术逻辑单元。ALU负责执行大多数位操作和逻辑指令。它还执行整数指令，不包括IMAD和IMUL。在NVIDIA Ampere架构芯片上，ALU流水线执行快速的FP 32到FP 16转换。<br>\n",
    "LSU: Load Store Unit, 加载存储单元。LSU流水线向L1 TEX单元发出用于全局、本地和共享内存的加载、存储、原子和归约指令。它还向L1 TEX单元发出特殊的寄存器读取（S2 R）、混洗和CTA级到达/等待屏障指令。<br>\n",
    "TMA: Tensor Memory Access Unit, 张量存储器访问单元。在全局内存和共享内存之间提供高效的数据传输机制，能够理解和遍历多维数据布局。<br>\n",
    "ADU: Address Divergence Unit, 地址分支单元。ADU负责分支/跳转的地址发散处理。它还支持恒定加载和块级屏障指令。<br>\n",
    "CBU：Convergence Barrier Unit，汇聚屏障单元。CBU负责曲速级收敛、屏障和分支指令。<br>\n",
    "TEX: Texture Unit, 纹理单元。SM纹理流水线将纹理和表面指令转发到L1TEX单元的TEXIN阶段。在FP64或Tensor流水线解耦的GPU上，纹理流水线也会转发这些类型的指令。<br>\n",
    "Uniform: Uniform Data Path, 统一数据路径。这个标量单元执行所有线程使用相同输入并生成相同输出的指令。<br>\n",
    "XU: Transcendental and Data Type Conversion Unit, 超越和数据类型转换单元。XU管道负责特殊函数，如sin、cos和倒数平方根。它还负责int到float和float到int类型的转换.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![statistic-1](./images/statistic-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析所有 warp 在内核执行期间所花费的周期数。warp state 描述 warp 是否准备好发出下一个指令。每条指令的 warp 周期定义了两条连续指令之间的延迟。该值越高，隐藏此延迟所需的 warp 并行度就越高。对于每个warp state，该图表显示了每个发出的指令在该状态下花费的平均周期数。stall 并不总是影响整体性能，也不是完全可以避免的。<br>\n",
    "<br>\n",
    "平均而言，该内核的每个warp在等待微调度器选择要发出的warp时会花费18.57个周期。未被选中的warp是指在该周期内没有被调度器选择发出的符合条件的warp。大量未被选中的warp通常意味着有足够多的warps来覆盖warp延迟，并且可以考虑减少活跃warps数量以可能增加缓存一致性和数据局部性。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![statistic-2](./images/statistic-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![statistic-3](./images/statistic-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.6 Occupancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "占用率(Occupancy)是指每个SM上活跃线程组(warp)的数量与可能的最大活跃线程组数量的比率。另一种看待占用率的方式是,它表示硬件处理线程组的能力中实际被使用的百分比。虽然较高的占用率并不总能带来更高的性能,但是低占用率会降低隐藏延迟的能力,从而导致整体性能下降。在执行过程中,理论占用率和实际达到的占用率之间存在较大差异,通常表示工作负载高度不均衡。占用率反映了GPU资源的利用情况,是评估CUDA程序性能的一个关键指标。过低的占用率会导致性能下降,需要分析并优化造成低占用率的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![occupancy-1](./images/occupancy-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![occupancy-2](./images/occupancy-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 程序示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有示例程序可见目录./nvidia_nsight/nsight_compute，您可以自行选择需要运行的程序，并使用ncu命令运行，然后进行一些简单的profile工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline<br>\n",
    "https://zhuanlan.zhihu.com/p/715022552<br>\n",
    "https://github.com/ifromeast/cuda_learning/blob/main/05_cuda_mode/ncu_profile/readme.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pytorch Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Profiler 是一个性能分析工具，专门用于分析和优化 PyTorch 模型的训练和推理性能。它提供了：<br>\n",
    "时间分析：测量操作执行时间<br>\n",
    "内存分析：跟踪内存分配和使用情况<br>\n",
    "GPU 利用率：分析 GPU 内核执行效率<br>\n",
    "可视化：通过 TensorBoard 提供直观的可视化界面<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 常用指令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 基础配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, tensorboard_trace_handler\n",
    "\n",
    "# 基础配置示例\n",
    "profiler_config = {\n",
    "    \"activities\": [\n",
    "        ProfilerActivity.CPU,      # 分析 CPU 活动\n",
    "        ProfilerActivity.CUDA,     # 分析 GPU 活动\n",
    "    ],\n",
    "    \"schedule\": torch.profiler.schedule(\n",
    "        skip_first=3,    # 跳过前3次step\n",
    "        wait=1,          # 等待1次step\n",
    "        warmup=1,        # 预热1次step\n",
    "        active=3,        # 活跃记录3次step\n",
    "        repeat=2         # 重复2轮\n",
    "    ),\n",
    "    \"on_trace_ready\": tensorboard_trace_handler(\"./logs\"),\n",
    "    \"record_shapes\": True,        # 记录张量形状\n",
    "    \"profile_memory\": True,       # 分析内存使用\n",
    "    \"with_stack\": True,           # 记录调用栈\n",
    "    \"with_flops\": True,           # 计算 FLOPs\n",
    "    \"with_modules\": True,         # 按模块分组\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 核心类和方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.profiler.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的 profiler 配置\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    \n",
    "    # 调度配置\n",
    "    schedule=torch.profiler.schedule(\n",
    "        skip_first=5,\n",
    "        wait=2,\n",
    "        warmup=2,\n",
    "        active=5,\n",
    "        repeat=1\n",
    "    ),\n",
    "    \n",
    "    # 输出配置\n",
    "    on_trace_ready=tensorboard_trace_handler(\"./logs\"),\n",
    "    \n",
    "    # 数据记录配置\n",
    "    record_shapes=True,      # 记录输入形状\n",
    "    profile_memory=True,     # 内存分析\n",
    "    with_stack=True,         # 调用栈信息\n",
    "    with_flops=True,         # FLOPs 计算\n",
    "    with_modules=False,      # 模块级分析\n",
    "    \n",
    "    # 实验性功能\n",
    "    experimental_config=torch.profiler._ExperimentalConfig(\n",
    "        profiler_metrics=torch.profiler.ProfilerMetrics.CUDA_LAUNCH_STATS\n",
    "    )\n",
    ") as prof:\n",
    "    # 训练循环\n",
    "    for step, data in enumerate(dataloader):\n",
    "        # 模型训练代码\n",
    "        train_step(data)\n",
    "        \n",
    "        # 重要：在每个step后调用\n",
    "        prof.step()\n",
    "        \n",
    "        if step >= 20:  # 限制分析步数\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调度器 (schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_profiler_schedule():\n",
    "    \"\"\"创建不同的调度策略\"\"\"\n",
    "    \n",
    "    # 方案1: 训练初期分析\n",
    "    early_training = schedule(\n",
    "        skip_first=0,   # 不跳过\n",
    "        wait=0,         # 不等待\n",
    "        warmup=1,       # 预热1步\n",
    "        active=5,       # 记录5步\n",
    "        repeat=1        # 只执行1轮\n",
    "    )\n",
    "    \n",
    "    # 方案2: 稳定期分析\n",
    "    stable_training = schedule(\n",
    "        skip_first=50,  # 跳过前50步\n",
    "        wait=5,         # 等待5步\n",
    "        warmup=2,       # 预热2步\n",
    "        active=10,      # 记录10步\n",
    "        repeat=2        # 执行2轮\n",
    "    )\n",
    "    \n",
    "    # 方案3: 周期性分析\n",
    "    periodic_analysis = schedule(\n",
    "        skip_first=10,\n",
    "        wait=5,\n",
    "        warmup=2,\n",
    "        active=3,\n",
    "        repeat=5        # 执行5轮，形成周期性分析\n",
    "    )\n",
    "    \n",
    "    return early_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 分析方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基础分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_analysis(prof):\n",
    "    \"\"\"基础性能分析\"\"\"\n",
    "    \n",
    "    print(\"=== 按CUDA时间排序 ===\")\n",
    "    print(prof.key_averages().table(\n",
    "        sort_by=\"cuda_time_total\", \n",
    "        row_limit=15\n",
    "    ))\n",
    "    \n",
    "    print(\"\\n=== 按CPU时间排序 ===\")\n",
    "    print(prof.key_averages().table(\n",
    "        sort_by=\"cpu_time_total\", \n",
    "        row_limit=15\n",
    "    ))\n",
    "    \n",
    "    print(\"\\n=== 按内存使用排序 ===\")\n",
    "    print(prof.key_averages().table(\n",
    "        sort_by=\"self_cpu_memory_usage\", \n",
    "        row_limit=10\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高级分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_analysis(prof):\n",
    "    \"\"\"高级分析技巧\"\"\"\n",
    "    \n",
    "    # 1. 按操作类型分组\n",
    "    print(\"=== 按操作类型分组 ===\")\n",
    "    key_averages = prof.key_averages()\n",
    "    print(key_averages.table(\n",
    "        sort_by=\"cuda_time_total\",\n",
    "        row_limit=10  # 可选：限制显示的行数\n",
    "    ))\n",
    "\n",
    "    # 2. 按输入形状分组\n",
    "    print(\"\\n=== 按输入形状分组 ===\")\n",
    "    key_averages_by_input_shape = prof.key_averages(group_by_input_shape=True)\n",
    "    print(key_averages_by_input_shape.table(\n",
    "        sort_by=\"cpu_time_total\",\n",
    "        row_limit=10  # 可选：限制显示的行数\n",
    "    ))\n",
    "    \n",
    "    # 3. 总统计信息\n",
    "    print(\"\\n=== 总体统计 ===\")\n",
    "    total_stats = prof.key_averages().total_average()\n",
    "    print(f\"总CPU时间: {total_stats.cpu_time_total / 1000:.2f} ms\")\n",
    "    print(f\"总CUDA时间: {total_stats.cuda_time_total / 1000:.2f} ms\")\n",
    "    \n",
    "    # 4. 事件统计\n",
    "    events = prof.events()\n",
    "    print(f\"\\n总事件数: {len(events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "内存分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_analysis(prof):\n",
    "    \"\"\"内存使用分析\"\"\"\n",
    "    \n",
    "    print(\"=== 内存分析 ===\")\n",
    "    \n",
    "    # CPU 内存分析\n",
    "    print(\"\\n--- CPU内存使用 ---\")\n",
    "    cpu_memory_table = prof.key_averages().table(\n",
    "        sort_by=\"self_cpu_memory_usage\",\n",
    "        row_limit=10\n",
    "    )\n",
    "    print(cpu_memory_table)\n",
    "    \n",
    "    # CUDA 内存分析\n",
    "    print(\"\\n--- CUDA内存使用 ---\")\n",
    "    cuda_memory_table = prof.key_averages().table(\n",
    "        sort_by=\"self_cuda_memory_usage\", \n",
    "        row_limit=10\n",
    "    )\n",
    "    print(cuda_memory_table)\n",
    "    \n",
    "    # 内存时间线\n",
    "    print(\"\\n=== 内存事件 ===\")\n",
    "    for event in prof.events():\n",
    "        if hasattr(event, 'cpu_memory_usage') and event.cpu_memory_usage > 0:\n",
    "            print(f\"操作: {event.name}, CPU内存: {event.cpu_memory_usage} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 实用工具函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "性能报告生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_performance_report(prof, model_name=\"model\"):\n",
    "    \"\"\"生成详细的性能报告\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "=== {model_name} 性能分析报告 ===\n",
    "\n",
    "执行统计:\n",
    "{prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20)}\n",
    "\n",
    "内存分析:\n",
    "{prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10)}\n",
    "\n",
    "CPU密集型操作:\n",
    "{prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)}\n",
    "\n",
    "关键指标:\n",
    "\"\"\"\n",
    "    \n",
    "    # 计算关键指标\n",
    "    total_stats = prof.key_averages().total_average()\n",
    "    cpu_time_ms = total_stats.cpu_time_total / 1000\n",
    "    cuda_time_ms = total_stats.cuda_time_total / 1000\n",
    "    \n",
    "    report += f\"\"\"\n",
    "- 总CPU时间: {cpu_time_ms:.2f} ms\n",
    "- 总CUDA时间: {cuda_time_ms:.2f} ms\n",
    "- CPU-CUDA时间比: {cpu_time_ms/cuda_time_ms:.2f}\n",
    "\"\"\"\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "瓶颈检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bottlenecks(prof, threshold_ms=10.0):\n",
    "    \"\"\"检测性能瓶颈\"\"\"\n",
    "    \n",
    "    print(\"=== 性能瓶颈检测 ===\")\n",
    "    \n",
    "    key_averages = prof.key_averages()\n",
    "    bottlenecks = []\n",
    "    \n",
    "    for event in key_averages:\n",
    "        cuda_time_ms = event.cuda_time_total / 1000\n",
    "        cpu_time_ms = event.cpu_time_total / 1000\n",
    "        \n",
    "        if cuda_time_ms > threshold_ms or cpu_time_ms > threshold_ms:\n",
    "            bottlenecks.append({\n",
    "                'name': event.key,\n",
    "                'cuda_time_ms': cuda_time_ms,\n",
    "                'cpu_time_ms': cpu_time_ms,\n",
    "                'input_shape': str(event.input_shapes) if hasattr(event, 'input_shapes') else 'N/A'\n",
    "            })\n",
    "    \n",
    "    # 打印瓶颈\n",
    "    for i, bottleneck in enumerate(sorted(bottlenecks, key=lambda x: x['cuda_time_ms'], reverse=True)):\n",
    "        print(f\"{i+1}. {bottleneck['name']}\")\n",
    "        print(f\"   CUDA时间: {bottleneck['cuda_time_ms']:.2f} ms\")\n",
    "        print(f\"   CPU时间: {bottleneck['cpu_time_ms']:.2f} ms\")\n",
    "        print(f\"   输入形状: {bottleneck['input_shape']}\")\n",
    "        print()\n",
    "    \n",
    "    return bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 界面介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hangcheng.dong/miniconda3/envs/bevfusion/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PyTorch Profiler 分析结果\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'basic_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     93\u001b[0m     example \u001b[38;5;241m=\u001b[39m ComprehensiveProfilerExample()\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_profiling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 67\u001b[0m, in \u001b[0;36mComprehensiveProfilerExample.run_profiling\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m prof\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 分析结果\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprof\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m, in \u001b[0;36mComprehensiveProfilerExample.analyze_results\u001b[0;34m(self, prof)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# 1. 基础分析\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mbasic_analysis\u001b[49m(prof)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 2. 高级分析\u001b[39;00m\n\u001b[1;32m     80\u001b[0m advanced_analysis(prof)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'basic_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.profiler import profile, schedule, tensorboard_trace_handler, ProfilerActivity\n",
    "\n",
    "class ComprehensiveProfilerExample:\n",
    "    def __init__(self):\n",
    "        self.model = self.create_model()\n",
    "        self.optimizer = optim.Adam(self.model.parameters())\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def create_model(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 10)\n",
    "        ).cuda()\n",
    "    \n",
    "    def run_profiling(self):\n",
    "        \"\"\"运行完整的性能分析\"\"\"\n",
    "        \n",
    "        # 配置profiler\n",
    "        prof = profile(\n",
    "            activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "            schedule=schedule(\n",
    "                skip_first=2,\n",
    "                wait=1,\n",
    "                warmup=1,\n",
    "                active=3,\n",
    "                repeat=2\n",
    "            ),\n",
    "            #on_trace_ready=tensorboard_trace_handler(\"./log\"),\n",
    "            record_shapes=True,\n",
    "            profile_memory=True,\n",
    "            with_stack=True,\n",
    "            with_flops=True\n",
    "        )\n",
    "        \n",
    "        prof.start()\n",
    "        \n",
    "        for step in range(20):\n",
    "            # 模拟训练步骤\n",
    "            inputs = torch.randn(32, 3, 32, 32).cuda()\n",
    "            targets = torch.randint(0, 10, (32,)).cuda()\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            \n",
    "            # 反向传播\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # 推进profiler\n",
    "            prof.step()\n",
    "            \n",
    "        prof.stop()\n",
    "        \n",
    "        # 分析结果\n",
    "        self.analyze_results(prof)\n",
    "        \n",
    "    def analyze_results(self, prof):\n",
    "        \"\"\"分析profiler结果\"\"\"\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"PyTorch Profiler 分析结果\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 1. 基础分析\n",
    "        basic_analysis(prof)\n",
    "        \n",
    "        # 2. 高级分析\n",
    "        advanced_analysis(prof)\n",
    "        \n",
    "        # 3. 内存分析\n",
    "        memory_analysis(prof)\n",
    "        \n",
    "        # 4. 生成报告\n",
    "        report = generate_performance_report(prof, \"CNN_Model\")\n",
    "        print(report)\n",
    "        \n",
    "        # 5. 瓶颈检测\n",
    "        bottlenecks = detect_bottlenecks(prof, threshold_ms=5.0)\n",
    "\n",
    "        # 6. 保存跟踪文件\n",
    "        prof.export_chrome_trace(\"comprehensive_trace.json\")\n",
    "        print(\"跟踪文件已保存: comprehensive_trace.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example = ComprehensiveProfilerExample()\n",
    "    example.run_profiling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上是界面介绍的示例函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 程序示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NVIDIA Nsight System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVIDIA Nsight Systems（nsys）作为NVIDIA官方提供的系统级性能分析工具，能够深入到硬件执行层面，提供从CPU线程调度到GPU kernel执行的完整时间线视图，帮助开发者：<br>\n",
    "精确定位性能瓶颈：无论是计算受限、内存带宽受限，还是CPU-GPU同步开销过大<br>\n",
    "量化优化效果：通过详细的性能指标对比，验证优化策略的实际效果<br>\n",
    "理解系统行为：深入理解现代GPU应用程序的执行机制和资源利用模式<br>\n",
    "在大模型训练、推理服务、科学计算等关键应用场景中，nsys已经成为性能工程师不可或缺的利器。掌握nsys的使用方法和分析技巧，对于任何从事GPU性能优化工作的开发者都具有重要的实用价值。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 常用指令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 总体流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 平台支持<br>\n",
    "Nsight Systems（nsys）是跨平台工具，支持 Windows、Linux、macOS，提供对应的 CLI 和 GUI 版本。<br>\n",
    "2. 数据采集<br>\n",
    "使用 nsys CLI 工具在目标环境（服务器 / 多 GPU 系统）上运行程序，收集性能数据。<br>\n",
    "生成 .nsys-rep 或 .qdrep 文件（请求文件 / trace 文件）。<br>\n",
    "3. 数据分析<br>\n",
    "将生成的 trace 文件拷贝到个人 PC 或分析工作站。<br>\n",
    "使用 nsys GUI 工具加载文件，可视化分析 GPU 时间线、CPU-GPU 交互、内存传输、Kernel 执行、库函数性能等。<br>\n",
    "可进行筛选、放大关键阶段、对比不同运行配置等操作。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 采集模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nsys 提供两种性能抓取方式：<br>\n",
    "1. 直接 Profile 模式<br>\n",
    "在命令行中预先指定要抓取的内容，以及起止条件（如持续时间、直到程序结束）。<br>\n",
    "工具会在达到条件时自动停止抓取。<br>\n",
    "优点：简单易用，适合全流程或确定阶段的性能采集；无需人工干预。<br>\n",
    "缺点：缺乏灵活性，无法根据程序实际运行情况临时调整抓取时机，容易产生无关数据或错过关键片段。<br>\n",
    "2. 交互式 Profile 模式<br>\n",
    "通过 nsys launch 启动目标进程，在另一终端中手动触发开始/结束。<br>\n",
    "可以在观察到程序运行状态后，再选择具体时段进行抓取。<br>\n",
    "同时交互式可以抓取多次。<br>\n",
    "优点：更灵活，能针对性捕捉不同阶段的性能数据，减少无效数据采集，文件体积也更小。<br>\n",
    "缺点：需要人工干预，操作复杂度更高，不适合无人值守或批量任务。<br>\n",
    "如果明确知道要分析的阶段，且希望流程自动化，推荐使用 直接 profile；<br>\n",
    "如果想在程序运行过程中观察状态，并灵活抓取关键时段，则 交互式 profile 更合适。<br>\n",
    "⚠️无论用哪种模式，收集时间尽量控制在1min以内，否则太大无法分析。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profile模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "profile模式：启动并分析新进程<br>  \n",
    "nsys profile torchrun train.py<br>\n",
    "参数说明：用torchrun代指实际的训练启动命令。<br>\n",
    "当前启动之后，nsys 会在train.py 进程结束之后生成一个nsys-rep后缀的文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lauch模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. 先启动任务</b><br>\n",
    "nsys launch torchrun train.py<br>\n",
    "<b>2. 新开一个窗口</b><br>\n",
    "<b>可以看到 sessions正在运行</b><br>\n",
    "nsys status<br>\n",
    "<b>3. 启动、结束</b><br>\n",
    "nsys start<br>\n",
    "nsys stop<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关键参数配置详解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "详细参数可见，有很多开关，这里仅仅常用收集参数。<br>\n",
    "https://docs.nvidia.com/nsight-systems/UserGuide/index.html<br>\n",
    "\n",
    "一般来说，使用如下命令收集：<br>\n",
    "\n",
    "nsys profile <br>\n",
    "  --trace cuda,osrt,nvtx,cudnn,cublas  <br>\n",
    "  --gpu-metrics-device=all <br>\n",
    "  --duration=60 <br>\n",
    "  --delay=120 <br>\n",
    "  --cuda-memory-usage true <br>\n",
    "  --output profile_log <br>\n",
    "    torchrun train.py <br>\n",
    "    \n",
    "    \n",
    " # 参数说明：\n",
    "   --trace cuda,osrt,nvtx,cudnn,cublas # 收集的内容，默认为cuda opengl nvtx osrt<br>\n",
    "   --gpu-metrics-device=all  # gpu相关指标<br>\n",
    "   --duration=30 \\ #收集时间为30s<br>\n",
    "   --delay=120 \\ # 延迟120s进行收集<br>\n",
    "   --cuda-memory-usage true \\ # 显存使用情况<br>\n",
    "     --output profile_log \\ # 指定输出路径和文件名<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意事项\n",
    "1. 延迟视情况而定，比如如果训练在30分钟之后拉起，需要延迟3600s\n",
    "2. 收集时间不宜过长，控制在60s之内\n",
    "3. 默认输入路径为当前路径，建议更改到有权限的输出路径，避免写到/tmp导致保存失败\n",
    "4. 输出路径多节点共享存储，输出文件名要有hostname之类的区别，否则会被覆盖写入保存失败\n",
    "5. 假设平台调度，存在某一个pod写完其他pod会被杀死的情况，建议使用launch方式收集\n",
    "6. ⚠️注意CPU权限配置，如果非管理员权限采集CPU详细信息，需要修改系统配置\n",
    "7. echo 0 | sudo tee /proc/sys/kernel/perf_event_paranoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 NVTX标记技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVTX（NVIDIA Tools Extension） 是 NVIDIA 提供的一套标注工具接口。<br>\n",
    "<br>\n",
    "它允许开发者在代码中插入 标记（marker） 或 区间（range），用来标识某段逻辑或操作。<br>\n",
    "<br>\n",
    "在使用 nsys 进行性能分析时，这些标记会显示在时间轴上，方便开发者快速定位和分析程序的关键阶段<br>\n",
    "<br>\n",
    "如下图所示，可以清晰的看到程序每一步运行所在的状态。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nvtx-1](./images/nvtx-1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python中NVTX的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install nvtx 即可使用：<br>\n",
    "主要使用方式：<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvtx\n",
    "\n",
    "@nvtx.annotate(\"data_loading\", color=\"blue\")\n",
    "def load_data():\n",
    "    # 数据加载逻辑\n",
    "    pass\n",
    "\n",
    "# 上下文管理器\n",
    "with nvtx.annotate(\"backward_pass\", color=\"red\"):\n",
    "    loss.backward()\n",
    "  \n",
    "# 手动标记1\n",
    "range_id = nvtx.start_range(\"my_code_range\", domain=\"my_domain\")\n",
    "loss.backward()\n",
    "nvtx.end_range(range_id)\n",
    "\n",
    "# 手动标记2\n",
    "import time\n",
    "import nvtx\n",
    "nvtx.push_range(\"my_code_range\", domain=\"my_domain\")\n",
    "model.train()\n",
    "nvtx.pop_range(domain=\"my_domain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新版的nvtx还提供了两种自动注解函数名字的方式：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接在代码中使用nvtx.Profile()\n",
    "import nvtx\n",
    "import time\n",
    "pr = nvtx.Profile()\n",
    "pr.enable()\n",
    "time.sleep(1)\n",
    "pr.disable()\n",
    "time.sleep(1)\n",
    "\n",
    "# 将nvtx作为命令行工具调用\n",
    "# 功能不用改源码，自动给所有函数加注释\n",
    "python -m nvtx script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "同时新版nsys可以对pytroch自动加函数nvtx了，非常方便。<br>\n",
    " --pytorch=autograd-nvtx  可以自动增加pytorch 函数的 nvtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nvtx-2](./images/nvtx-2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 界面介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引言：CPU-GPU协同的编程范式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习训练或推理中，CPU 与 GPU 协同执行是性能分析的基础。理解这一协同机制对于优化深度学习系统性能至关重要。通常流程可以拆解为以下几个层次："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 应用层（Python/Pytorch）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>用户代码层面</b>：大多数深度学习逻辑写在 Python 层（如 nn.Module、loss.backward()），这层代码主要负责模型定义、训练循环控制和数据流管理。<br>\n",
    "\n",
    "<b>框架调度层面</b>：PyTorch 作为中间层，封装了底层算子调用，通过 C++ ATen 库和 CUDA Runtime 将高级操作转换为具体的 GPU kernel 调用。每个 PyTorch 操作（如 torch.matmul、torch.relu）会被分解为一个或多个 CUDA kernel。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>关键理解</b>：<br>\n",
    "\n",
    "Python 代码本身永远不在 GPU 上运行<br>\n",
    "每次张量操作都会触发 kernel launch 开销，频繁的小操作会导致性能损失<br>\n",
    "算子融合（operator fusion）可以减少 kernel 启动次数，提升整体性<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Host 与 Device 的内存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 GPU 编程中，Host 一般代指 CPU 及其相关资源，Device 一般代指 GPU 及其相关资源。理解两者的内存特性和数据传输机制是性能优化的关键。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "内存架构对比<br>\n",
    "\n",
    "Host Memory（CPU 内存，DDR）：<br>\n",
    "数据源头：Dataloader 首先将批次数据从存储设备加载到系统内存<br>\n",
    "代码执行：存储模型代码、Python 解释器、深度学习框架逻辑等运行时环境<br>\n",
    "容量特点：容量大（通常 64-512GB），成本相对较低<br>\n",
    "性能特点：访问延迟较高（~100-300ns），带宽相对有限（~100GB/s）<br>\n",
    "适用场景：数据预处理、存储、控制逻辑执行<br>\n",
    "Device Memory（GPU 显存，HBM）：<br>\n",
    "计算要求：GPU 所有计算必须在显存中完成，这是 GPU 架构的硬性要求<br>\n",
    "容量限制：容量相对有限（通常 16-80GB），成本较高，是深度学习模型规模的重要约束<br>\n",
    "性能优势：超高带宽（~4TB/s），低延迟访问，专为并行计算优化<br>\n",
    "存储内容：模型参数、输入数据、中间激活值、梯度、优化器状态等训练/推理所需的所有数据<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据传输路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现代深度学习系统中的数据传输主要包含三种模式：<br>\n",
    "\n",
    "H2D (Host-to-Device) 传输：<br>\n",
    "传输内容：训练数据、模型参数、配置信息从 CPU 内存传输到 GPU 显存<br>\n",
    "典型场景：批次数据上传、模型权重初始化、超参数传递<br>\n",
    "性能瓶颈：PCIe 带宽限制（~32GB/s），通常是训练流水线的主要瓶颈<br>\n",
    "优化策略：Pinned Memory、异步传输、数据预取<br>\n",
    "\n",
    "D2H (Device-to-Host) 传输：<br>\n",
    "传输内容：训练结果、损失值、模型检查点从 GPU 显存传输到 CPU 内存<br>\n",
    "典型场景：损失值回传、模型保存、中间结果验证、调试信息提取<br>\n",
    "频率特点：通常频率较低，但对调试和监控至关重要<br>\n",
    "注意事项：会触发 GPU-CPU 同步，可能打断训练流水线<br>\n",
    "\n",
    "D2D (Device-to-Device) 传输：<br>\n",
    "传输内容：GPU 间直接数据交换，bypass CPU 和系统内存<br>\n",
    "典型场景：<br>\n",
    "分布式训练：梯度同步（AllReduce）、参数广播（Broadcast）<br>\n",
    "模型并行：不同 GPU 负责模型的不同部分，需要交换中间激活<br>\n",
    "数据并行：多 GPU 间的负载均衡和结果聚合<br>\n",
    "技术实现：<br>\n",
    "NVLink：NVIDIA GPU 间的专用高速互联（~600GB/s），NVSwitch支持多 GPU 全连接的交换矩阵<br>\n",
    "RDMA：跨节点的高速网络互联<br>\n",
    "性能优势：带宽远高于 PCIe，延迟更低，是大规模分布式训练的基础<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stream 并发与 CPU↔GPU 协作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CUDA Stream 机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream 概念：CUDA Stream 是 GPU 上的任务执行队列，保证队列内任务按顺序执行：<br>\n",
    "CPU 将任务（kernel 启动、内存拷贝、同步操作）提交到指定 Stream<br>\n",
    "Stream 内串行，Stream 间并行：不同 Stream 上的任务可以并发执行<br>\n",
    "默认使用 \"default stream\"，也可创建多个用户 Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 执行模式对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "异步模式（默认推荐）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU 提交任务后立即返回，不等待 GPU 完成\n",
    "x_gpu = x.cuda()          # 异步内存拷贝\n",
    "y = torch.matmul(x_gpu, w)  # 异步 kernel 启动\n",
    "z = torch.relu(y)         # 异步 kernel 启动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优势：<br>\n",
    "CPU 将任务提交到 Stream 后立即返回，可以并行准备下一个 batch<br>\n",
    "GPU 在后台执行，CPU 与 GPU 时间重叠<br>\n",
    "数据传输和计算可以在不同 Stream 上并发，提升整体利用率<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同步模式（阻塞调用）：<br>\n",
    "export CUDA_LAUNCH_BLOCKING=1  # 环境变量强制同步<br>\n",
    "<br>\n",
    "特点：<br>\n",
    "强制 CPU 等待每个 GPU 操作完成<br>\n",
    "CPU 与 GPU 都失去并行性，性能显著下降<br>\n",
    "主要用于调试定位错误（便于确定具体哪个 kernel 出错）<br>\n",
    "由于默认异步执行，CPU 可能在 GPU 尚未完成计算时就继续执行后续代码，导致：<br>\n",
    "数据竞争：访问尚未计算完成的结果<br>\n",
    "时序错误：依赖关系被破坏<br>\n",
    "错误的性能测量：计时不准确<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用同步方式<br>\n",
    "PyTorch 同步 API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.synchronize()        # 等待所有 Stream 完成\n",
    "torch.cuda.synchronize(device)  # 等待指定设备完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA 原生同步："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "cuda.Context.synchronize()      # 等待当前 context 完成\n",
    "stream.synchronize()            # 等待特定 stream 完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隐式同步场景：<br>\n",
    "数据回传：.cpu() 或 .numpy() 会触发隐式同步<br>\n",
    "跨设备操作：不同 GPU 间的数据拷贝<br>\n",
    "Host 端访问：tensor.item() 获取标量值<br>\n",
    "<br>\n",
    "典型应用场景<br>\n",
    "精确计时 Benchmark：<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "start_time = time.time()\n",
    "result = model(input_data)\n",
    "torch.cuda.synchronize()  # 确保计算完成\n",
    "end_time = time.time()\n",
    "#调试错误定位：\n",
    "# 每个操作后同步，精确定位出错位置\n",
    "x = torch.matmul(a, b)\n",
    "torch.cuda.synchronize()  # 如果上一行出错，这里会抛出异常"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU 计算模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kernel 执行机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Launch 过程：<br>\n",
    "CPU 通过 CUDA Runtime API（如 cudaLaunchKernel）启动 kernel<br>\n",
    "配置执行参数：grid 维度、block 维度、shared memory 大小等<br>\n",
    "异步提交到 GPU 执行队列，CPU 可立即返回继续执行<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 大规模并行架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线程层次结构：<br>\n",
    "Thread：最小执行单元，每个线程处理一个数据元素<br>\n",
    "Warp：32个线程为一组，SIMD 执行（单指令多数据）<br>\n",
    "Block：多个 warp 组成，共享 shared memory 和同步原语<br>\n",
    "Grid：多个 block 组成，对应一次 kernel 启动<br>\n",
    "调度特点：<br>\n",
    "GPU 拥有数千个 CUDA core，可同时执行数万个线程<br>\n",
    "warp 级调度：当一个 warp 等待内存访问时，调度器切换到其他warp<br>\n",
    "通过大量线程掩盖访存延迟，实现高吞吐量计算<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 内存层次结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显存（HBM - High Bandwidth Memory）：<br>\n",
    "存放模型参数、输入数据、中间激活、梯度等<br>\n",
    "带宽极高（~1TB/s）但延迟相对较大（~300-500 cycles）<br>\n",
    "<br>\n",
    "L2 Cache：<br>\n",
    "所有 SM（Streaming Multiprocessor）共享<br>\n",
    "容量通常几 MB，用于缓存频繁访问的数据<br>\n",
    "<br>\n",
    "Shared Memory：<br>\n",
    "Block 内线程共享的快速存储（~100 cycles 延迟）<br>\n",
    "容量小（48-164KB），需要程序员手动管理<br>\n",
    "<br>\n",
    "寄存器文件：<br>\n",
    "线程私有，延迟最低（1-2 cycles）<br>\n",
    "数量有限，寄存器不足会导致\"spill\"到显存<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常见性能瓶颈与优化策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Host-Device 传输瓶颈\n",
    "问题表现：<br>\n",
    "PCIe 带宽利用率高（>80%）<br>\n",
    "GPU 计算单元空闲等待数据<br>\n",
    "<br>\n",
    "优化策略：<br>\n",
    "启用 pinned memory：DataLoader(pin_memory=True)<br>\n",
    "异步数据传输：使用多个 Stream 并发传输<br>\n",
    "数据预处理前移：在 GPU 上进行数据增强<br>\n",
    "减少传输频率：增大 batch size，减少传输次数<br>\n",
    "\n",
    "2. CPU 成为瓶颈<br>\n",
    "问题表现：<br>\n",
    "CPU 利用率持续高位<br>\n",
    "GPU 利用率波动，出现周期性空闲<br>\n",
    "<br>\n",
    "根本原因：<br>\n",
    "Python GIL 限制：单线程执行限制<br>\n",
    "数据加载慢：磁盘 I/O 或预处理复杂<br>\n",
    "频繁同步：过多的 .cpu() 或显式同步调用<br>\n",
    "<br>\n",
    "优化策略：<br>\n",
    "多进程 DataLoader：DataLoader(num_workers=4-8)<br>\n",
    "数据缓存：使用 SSD 或内存缓存训练数据<br>\n",
    "减少同步点：避免不必要的 CPU-GPU 同步<br>\n",
    "JIT 编译：torch.jit.script 减少 Python 解释开销<br>\n",
    "\n",
    "3. Kernel 启动开销过大\n",
    "问题表现：<br>\n",
    "大量小 kernel（执行时间 < 10μs）<br>\n",
    "GPU timeline 呈现\"锯齿状\"，kernel 间空隙明显<br>\n",
    "<br>\n",
    "优化策略：<br>\n",
    "算子融合：将多个操作合并为单个 kernel<br>\n",
    "向量化操作：使用张量运算替代循环<br>\n",
    "批处理：增加单次操作的数据量<br>\n",
    "Graph 模式：torch.fx 或 torch.jit 进行计算图优化<br>\n",
    "\n",
    "4. Stream 并发不足\n",
    "问题表现：<br>\n",
    "GPU timeline 存在明显\"空洞\"<br>\n",
    "数据传输与计算无法重叠<br>\n",
    "多 GPU 系统中存在负载不均<br>\n",
    "<br>\n",
    "优化策略：<br>\n",
    "多 Stream 设计：分离计算、通信、数据传输<br>\n",
    "Pipeline 并行：多个 batch 流水线处理<br>\n",
    "异步执行：避免不必要的同步操作<br>\n",
    "负载均衡：合理分配任务到不同 Stream<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 总览视图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将抓取好的 .nsys-rep 文件拖入 GUI 后，界面主要分为三个功能区域。需要特别注意的是，GUI 版本必须高于或等于 CLI 版本才能正常打开和解析文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overview-1](./images/overview-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 区域1：历史记录区<br>\n",
    "主要显示过往打开过的性能分析文件，属于历史记录和快速访问区域。该区域会保存最近使用的项目文件路径，方便用户快速重新加载之前的分析结果，日常性能分析中无需过多关注。<br>\n",
    "2. 区域2: 主功能导航区<br>\n",
    "<b>Analysis Summary（分析总览）</b><br>\n",
    "对整体性能进行全面总结，是性能分析的起始点：<br>\n",
    "软硬件信息：CPU 型号、GPU 规格、内存容量、CUDA 版本等系统配置<br>\n",
    "环境变量：影响性能的关键环境设置（如 CUDA_VISIBLE_DEVICES、OMP_NUM_THREADS 等）<br>\n",
    "进程与线程统计：不同线程的数量分布和执行特征<br>\n",
    "CPU 利用率概览：整体 CPU 使用情况和负载分布<br>\n",
    "GPU 利用率摘要：GPU 计算单元、内存带宽的整体使用效率<br>\n",
    "这是一个非常实用的性能概览面板，建议每次分析时首先查看。<br>\n",
    "<br>\n",
    "<b>Timeline View（时间线视图）</b><br>\n",
    "最核心的 CPU-GPU 协作时间线，是性能瓶颈分析的主战场：<br>\n",
    "多层时间线：CPU 线程、GPU Stream、内存传输等多维度并行展示<br>\n",
    "事件可视化：kernel 执行、API 调用、内存拷贝等事件的时序关系<br>\n",
    "交互式缩放：支持时间轴的放大缩小，精确定位性能热点<br>\n",
    "依赖关系：直观显示 CPU-GPU 间的同步点和数据依赖<br>\n",
    "这是分析性能瓶颈的核心视图，大部分性能问题都能在此找到答案。<br>\n",
    "<br>\n",
    "<b>Diagnostics Summary（诊断摘要）</b><br>\n",
    "显示抓取过程中的技术细节：<br>\n",
    "进程注入信息：profiling 工具如何附加到目标进程<br>\n",
    "采样配置：数据收集的频率和范围设置<br>\n",
    "系统状态：抓取期间的系统资源状态<br>\n",
    "错误或警告：数据收集过程中遇到的问题<br>\n",
    "实用性相对较小，主要用于排查 profiling 工具本身的问题。<br>\n",
    "<br>\n",
    "<b>Files（文件管理）</b><br>\n",
    "列出抓取到的各类信息文件：<br>\n",
    "原始数据文件：底层性能计数器数据<br>\n",
    "处理后的报告：各种格式的分析结果<br>\n",
    "导出选项：支持将特定数据导出为 CSV、JSON 等格式<br>\n",
    "文件大小统计：帮助理解数据收集的完整性<br>\n",
    "可根据具体分析需求进行查看或导出，便于后续深入分析或报告生成。<br>\n",
    "\n",
    "3. 区域 3：详细分析区（仅在 Timeline View 下激活）<br>\n",
    "当选择 Timeline View 后，区域 3 会动态显示多个专业分析面板：<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overview-2](./images/overview-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Event View（事件视图）</b><br>\n",
    "分析当前选中时间区间内的具体事件：<br>\n",
    "事件列表：详细显示选中时间段内发生的所有操作<br>\n",
    "事件属性：每个事件的持续时间、参数、返回值等详细信息<br>\n",
    "过滤功能：可按事件类型、持续时间等条件筛选<br>\n",
    "统计信息：事件频次、平均耗时等聚合数据<br>\n",
    "<br>\n",
    "<b>System Status View（系统状态视图）</b><br>\n",
    "汇总各种性能指标与系统状态：<br>\n",
    "资源利用率：实时 CPU、GPU、内存使用情况<br>\n",
    "温度和功耗：硬件运行状态监控<br>\n",
    "带宽利用率：PCIe、内存带宽的使用效率<br>\n",
    "队列深度：GPU Stream 和 CPU 任务队列状态<br>\n",
    "这是性能瓶颈定位的重要参考面板。<br>\n",
    "<br>\n",
    "<b>Expert System View（专家系统视图）</b><br>\n",
    "AI 驱动的性能优化建议引擎：<br>\n",
    "瓶颈识别：自动检测 CPU idle、GPU underutilization 等问题<br>\n",
    "优化建议：针对不同性能问题给出具体的代码级优化建议<br>\n",
    "最佳实践：基于检测到的模式推荐行业最佳实践<br>\n",
    "量化分析：给出优化后的预期性能提升幅度<br>\n",
    "对于性能优化新手特别有价值。<br>\n",
    "<br>\n",
    "<b>Top-Down View / Bottom-Up View（调用堆栈分析）</b><br>\n",
    "Top-Down View（自顶向下）：<br>\n",
    "从程序入口开始，逐层展示函数调用关系<br>\n",
    "适合理解程序整体执行流程和主要时间消耗<br>\n",
    "便于识别高层次的性能瓶颈<br>\n",
    "<br>\n",
    "<b>Bottom-Up View（自下向上）</b>：<br>\n",
    "从最底层的 kernel 或函数开始，向上聚合调用关系<br>\n",
    "适合定位具体的性能热点函数<br>\n",
    "便于发现被多处调用的共同瓶颈<br>\n",
    "这两个视图互为补充，用于深入分析函数调用路径及精确定位性能瓶颈。<br>\n",
    "<br>\n",
    "<b>Flat View（平面视图）</b><br>\n",
    "显示各函数或事件的扁平化统计信息：<br>\n",
    "执行时间排序：按照总耗时或平均耗时排列函数<br>\n",
    "调用频次统计：显示每个函数的调用次数<br>\n",
    "性能热点标识：快速识别最耗时的操作<br>\n",
    "比例分析：各函数在总执行时间中的占比<br>\n",
    "便于快速定位性能热点，是性能优化的重要入口。<br>\n",
    "<br>\n",
    "使用建议：建议按照 Analysis Summary → Timeline View → System Status View → Expert System View → Event View 的顺序进行分析，从宏观到微观，从概览到细节，逐步深入性能瓶颈的根因。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 GPU Timeline 完整视图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要内容：CUDA API 调用时序- GPU Kernel 执行时间线- Memory Transfer 可视化- Stream 并发情况<br>\n",
    "价值：展示 GPU 上的执行全貌，帮助定位 Kernel 重叠度、数据传输与计算的重叠情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>内容概览</b><br>\n",
    "在选择 Timeline 视图后，区域 2 会呈现三栏内容：<br>\n",
    "CPU：展示进程在 CPU 上的分布情况。<br>\n",
    "GPU：由于开启了 GPU Metric，可以看到部分 GPU 硬件指标。<br>\n",
    "Processes：显示训练的主进程以及数据加载进程。当前是单机八卡训练，也就是说有8个训练主进程和n个dataset worker。<br>\n",
    "<br>\n",
    "当我们展开某个 Processes 项时，区域 2.2 会进一步分为两栏：<br>\n",
    "CUDA HW：对应 GPU 侧的执行情况，包含 Stream（时间维度上的执行流）和 Kernel（瞬时空间维度上的计算单元）。<br>\n",
    "Threads：对应 CPU 侧的执行情况，主要展示 Python 中的线程活动。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gputimeline-1](./images/gputimeline-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS Runtime Library（操作系统运行时库）<br>\n",
    "指由CPU发起并在CPU上执行的系统级操作，包括线程管理、内存分配、文件I/O等基础系统调用。<br>\n",
    "<br>\n",
    "CUDA HW（CUDA硬件层）<br>\n",
    "指实际在GPU硬件上执行的计算操作，主要包括各种CUDA kernel的执行过程，这些操作直接利用GPU的并行计算能力。<br>\n",
    "<br>\n",
    "CUDA API（CUDA应用程序接口）<br>\n",
    "指由CPU发起、用于操控GPU的接口调用，如内存分配(cudaMalloc)、数据传输(cudaMemcpy)、kernel启动等操作。这些API在CPU上执行，但其目的是管理和调度GPU资源。<br>\n",
    "<br>\n",
    "简而言之：<br>\n",
    "OS Runtime Library：CPU → CPU（系统操作）<br>\n",
    "CUDA HW：GPU → GPU（实际计算）<br>\n",
    "CUDA API：CPU → GPU（GPU管理）<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>操作方式</b><br>\n",
    "时间维度缩放<br>\n",
    "缩放操作：将鼠标悬停在 Timeline 视图后，按住 Cmd 键（Mac）或 Ctrl 键（Windows/Linux）+ 滚轮滚动，可以对时间轴进行精确缩放<br>\n",
    "缩放中心：缩放会以鼠标当前位置为中心点进行，便于快速定位到感兴趣的时间段<br>\n",
    "缩放范围：支持从毫秒级到纳秒级的多层次缩放，满足不同粒度的性能分析需求<br>\n",
    "<br>\n",
    "<b>聚焦分析</b><br>\n",
    "Filter & Zoom In：选定区域后可以过滤并放大到当前区域，专注分析特定时间段的性能表现<br>\n",
    "上下文保持：放大后仍可通过导航操作查看相邻时间段的上下文信息<br>\n",
    "<br>\n",
    "<b>Y 轴缩放</b><br>\n",
    "垂直缩放：右上角的加减号按钮可以控制 Y 轴方向的显示密度<br>\n",
    "适应内容：当进程或线程数量较多时，可以通过 Y 轴缩放调整显示效果<br>\n",
    "层级管理：帮助在复杂的多进程、多线程场景下保持界面清晰<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gputimeline-2](./images/gputimeline-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 CPU-GPU 交互分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要内容：Host–Device 数据传输瓶颈识别- CPU 等待 GPU 的空闲时间- 异步调用效率分析<br>\n",
    "价值：揭示 CPU 与 GPU 协同是否高效，发现数据传输或同步点带来的性能损耗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 多层次性能指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要内容：GPU 利用率统计- Memory 带宽利用率- Kernel Launch 开销- Context Switch 分析<br>\n",
    "价值：提供量化指标，帮助分析算力使用是否饱和、是否存在频繁小 Kernel 等低效模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Status System View</b><br>\n",
    "这里会有各类统计信息，非常关键，可以着重去分析，这里取两个例子来说明。<br>\n",
    "GPU kernel Summary：这里会统计所有的GPU上执行的kernel， 可以看到当前训练程序有 50%的时间都在处理前两个算子，可以考虑着重优化。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sysmem-1](./images/sysmem-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时关注到CUDA API Summary中，cudaDeviceSynchronize 占比 53.9%，意味着超过一半的执行时间消耗在设备同步上，调用频繁：256 次调用，平均每次 23.7ms，说明存在频繁的强制同步<br>\n",
    "\n",
    "这个API会强制 CPU 等待 GPU 完成所有操作，影响 CPU-GPU 异步执行优势，可能是代码中过多使用 .cpu(), .numpy(), .item() 等隐式同步操作，或者调试代码中的显式 torch.cuda.synchronize() 未清理<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sysmem-2](./images/sysmem-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>timeline分析</b><br>\n",
    "\n",
    "从timeline中可以看到memcpy 的操作，H2D，这意味着数据从内存加载到了显存中，一般这代表每个训练迭代的开始，两次memcpy代表一次迭代时间。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sysmem-3](./images/sysmem-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选中给定时间段，对应的Stats System View 信息也会同步的更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sysmem-4](./images/sysmem-4.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zoom in之后可以看到，有非常明显的一段空白，也就是说这段时间GPU利用率非常低，当我们展开CUDA API和Stream 的kernel时可以发现，有非常多的h2d、d2h的操作，极大的影响了训练的进程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sysmem-5](./images/sysmem-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 系统资源监控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要内容：GPU 温度 / 功耗- PCIe 带宽使用情况- 多 GPU 系统的负载均衡<br>\n",
    "价值：从硬件维度辅助性能调优，避免功耗过高、PCIe 拥塞或 GPU 负载不均衡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 第三方库透明分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要内容：cuDNN、cuBLAS 等库性能- 自定义 CUDA kernel 性能- 驱动层面的性能瓶颈<br>\n",
    "价值：无需修改库源码即可分析性能，定位到算子级 / kernel 级瓶颈，区分是库问题还是自定义代码问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 使用流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际应用中，使用nsys进行性能分析主要涉及两种典型场景：<br>\n",
    "\n",
    "第一种场景：性能瓶颈定位分析 当程序运行性能不达预期或存在明显的性能瓶颈时，需要通过nsys深入分析系统的执行过程，识别关键的性能瓶颈点，为后续的针对性优化提供数据支撑。<br>\n",
    "\n",
    "第二种场景：性能差异对比分析 当程序在不同环境、配置或输入条件下表现出显著的性能差异时（例如在某些情况下运行正常，而在其他情况下出现性能问题），需要通过nsys对比分析不同场景下的执行特征，找出导致性能差异的根本原因。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 程序性能瓶颈点分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "寻找程序的性能瓶颈并不是一件很简单的事情。<br>\n",
    "<br>\n",
    "几个简单的原则是：<br>\n",
    "\n",
    "1. 自顶向下的分析策略<br>\n",
    "首先从整体时间线视图观察程序的总体执行模式<br>\n",
    "识别占用时间最长的阶段或操作<br>\n",
    "逐步深入到具体的kernel或API调用层面<br>\n",
    "\n",
    "2. 关注关键性能指标<br>\n",
    "GPU利用率：检查GPU是否充分利用，避免空闲等待<br>\n",
    "内存带宽利用率：分析是否存在内存访问瓶颈<br>\n",
    "kernel执行时间：找出耗时最长的计算kernel<br>\n",
    "数据传输开销：检查Host-Device间的数据拷贝是否过频繁<br>\n",
    "\n",
    "3. 识别常见瓶颈模式<br>\n",
    "计算密集型瓶颈：kernel执行时间过长<br>\n",
    "内存带宽瓶颈：内存访问模式不优化<br>\n",
    "同步等待瓶颈：频繁的CPU-GPU同步操作<br>\n",
    "资源竞争瓶颈：多stream间的资源争用<br>\n",
    "一个从头到尾的gpu利用率蓝条是最优的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 程序性能差异点分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑如下场景，当前进程在机器1上是正常运行的，但是在机器2上却无法复现对应的性能，这个时候需要通过对比分析来找出差异点。<br>\n",
    "典型的差异分析场景包括：<br>\n",
    "1. 硬件环境差异<br>\n",
    "不同GPU型号或架构导致的性能差异<br>\n",
    "内存容量或带宽规格的不同<br>\n",
    "PCIe版本或CPU性能的差异<br>\n",
    "2. 软件环境差异<br>\n",
    "CUDA驱动版本不一致<br>\n",
    "系统负载或后台进程的影响<br>\n",
    "编译器优化级别或链接库版本差异<br>\n",
    "3. 差异点定位方法<br>\n",
    "并行对比分析：同时在两台机器上运行nsys，对比相同时间段的执行特征<br>\n",
    "关键指标对比：重点比较kernel执行时间、内存使用模式、GPU利用率等核心指标<br>\n",
    "执行路径对比：检查程序是否在不同环境下走了不同的执行分支<br>\n",
    "资源使用对比：分析内存分配模式、stream使用情况等是否存在差异<br>\n",
    "4. 分析工作流程<br>\n",
    "收集两个环境下的完整nsys profile数据<br>\n",
    "使用timeline视图进行宏观对比，识别明显的执行模式差异<br>\n",
    "深入到具体的API调用和kernel执行层面进行微观分析<br>\n",
    "结合系统环境信息，定位导致差异的根本原因<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bevfusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
